{
 "cells": [
  {
   "cell_type": "code",
   "id": "3027aad445a8ca34",
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "857d764bfbe99f68",
   "metadata": {},
   "source": [
    "import json\n",
    "import logging\n",
    "\n",
    "logging.basicConfig(level=logging.WARNING) # set your preferred logging level here\n",
    "\n",
    "# we import the things we need (obviously)\n",
    "from data.VulnerabilityReport import create_from_flama_json # this is the function that creates the VulnerabilityReport object from the json data\n",
    "from ai.LLM.LLMServiceStrategy import LLMServiceStrategy "
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "f490c5d5b210be2b",
   "metadata": {},
   "source": [
    "from pathlib import Path\n",
    "\n",
    "data_folder = Path('../../data/') # Please change to the folder, Dataset.json is located in\n",
    "# We need the json data, so we are loading it from the file\n",
    "with open(data_folder / Path('Dataset.json')) as f:\n",
    "    data = json.load(f)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Choose your Strategy\n",
    "Right now, we support two strategies listed below.\n",
    "Execute the one you like more :)"
   ],
   "id": "133dc5fc298ba3d8"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Option 1) OpenAI - Remote\n",
    "Uses OpenAIs GPT-4o by default.\n",
    "\n",
    "Relatively cheap and quite good.\n"
   ],
   "id": "cbb43a8273ab2e09"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from ai.LLM.Strategies.OpenAIService import OpenAIService\n",
    "\n",
    "my_strategy = OpenAIService()"
   ],
   "id": "a17be348b6b7294a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Option 2) Anthropic - Remote\n",
    "Uses Anthropics Claude 3 Opus by default.\n",
    "\n",
    "Almost perfect but quite expensive.\n"
   ],
   "id": "33ce7bb1fd20e336"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from ai.LLM.Strategies.OpenAIService import OpenAIService\n",
    "\n",
    "my_strategy = OpenAIService()"
   ],
   "id": "901c5824178df8bb",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Option 3) OLLAMA - Local\n",
    "Here, you can choose the model you want to use. If you don't know which one to choose, you can just leave it empty and the default model will be used. Available models can be found [here](https://ollama.com/library).\n",
    "\n",
    "The performance (both in time and quality) depends heavily on the model used."
   ],
   "id": "3357a17a826c90f7"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from ai.LLM.Strategies.OLLAMAService import OLLAMAService # this is the service that uses ollama to generate solution\n",
    "\n",
    "model_name=None # but can be anything from here https://ollama.com/library\n",
    "my_strategy = OLLAMAService(model_name=model_name)"
   ],
   "id": "845858d36a9b448d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# LLM Service\n",
    "This is the service that uses the strategy you chose. It is the top abstraction layer that will be used to generate solutions."
   ],
   "id": "b70749b293caeb08"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "llm_service = LLMServiceStrategy(my_strategy)",
   "id": "9750ed3f60f2a320",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Data Setup\n",
    "We instance a vulnerability report object and add findings to it. We also sort the findings by severity.\n",
    "This object takes the LLM service and acts as main abstraction layer for the data.\n"
   ],
   "id": "b7f9f9f8d546dcbb"
  },
  {
   "cell_type": "code",
   "id": "926f7b0460c0f790",
   "metadata": {},
   "source": [
    "n=5 # number of findings to import\n",
    "vulnerability_report = create_from_flama_json(data, n = n, llm_service=llm_service) # here, we create the VulnerabilityReport object, consisting of a list of Finding objects which each have Solution objects. We pass the llm_service to the VulnerabilityReport object, but this can also just be omitted, in which case it will be created in each Finding object.\n",
    "vulnerability_report.sort() # this will sort the findings by severity"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "c053459ec572c675",
   "metadata": {},
   "source": "# Lets get going with AI - ðŸš€ðŸŒ•"
  },
  {
   "cell_type": "markdown",
   "id": "ecc63b904e7ad48",
   "metadata": {},
   "source": [
    "## First: We add categories to the Findings\n",
    "This will help us later to improve prompts (hopefully)"
   ]
  },
  {
   "cell_type": "code",
   "id": "14edeb4a26eeab5e",
   "metadata": {},
   "source": [
    "vulnerability_report.add_category() # this will add categories to the findings"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "bef753bd813064d3",
   "metadata": {},
   "source": [
    "## Then we add solutions ðŸŽ‰\n",
    "The function below adds long and short solutions to the findings. It also adds keywords for future research.\n",
    "\n",
    "For this function, we have multiple layers that may catch errors. So if you see a warning but no error afterwards, the waring was caught. Only if you see an error, data wasn't generated correctly."
   ]
  },
  {
   "cell_type": "code",
   "id": "d51599fff12405ff",
   "metadata": {},
   "source": [
    "vulnerability_report.add_solution(long=True, short=True, search_term=True) # this will add solutions to the findings"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Last but not least: Results\n",
    "We save and display results in the coming cells."
   ],
   "id": "a4ce1d49107d0bab"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "with open(data_folder / Path(f'VulnerabilityReport_{n if n !=-1 else \"all\"}_' + my_strategy.get_model_name().replace(\":\",\"_\") +'.json'), 'w') as f:\n",
    "    f.write(str(json.dumps(vulnerability_report.to_dict())))"
   ],
   "id": "73d0454da9633cc0",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "c827dd06",
   "metadata": {},
   "source": [
    "from IPython.display import HTML, Markdown\n",
    "Markdown(vulnerability_report.to_html(table=True))\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "HTML(str(vulnerability_report).replace('\\n', '<br />'))\n",
   "id": "496eb3b60477c4b4",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "c1a753a332bd90d7",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
